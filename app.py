# streamlit_app.py â€“ Cultural Ethics Simulator (Scenario A/B ë²„ì „)

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from scipy.stats import entropy, pearsonr
import openai  # GPT ìš”ì•½ ê¸°ëŠ¥ ì“°ë©´ í•„ìš”, ì•ˆ ì“°ë©´ ì—ëŸ¬ ë‚˜ë„ ë¬´ì‹œ ê°€ëŠ¥

# ==================== App Config ====================
st.set_page_config(page_title="Ethics GPT Sim", layout="wide")
st.title("ğŸŒ Global AI Ethics Simulator")

# ==================== Configuration ====================
CULTURES = {
    "USA":       {"emotion": 0.3,  "social": 0.1,  "identity": 0.3,  "moral": 0.3},
    "CHINA":     {"emotion": 0.1,  "social": 0.5,  "identity": 0.2,  "moral": 0.2},
    "EUROPE":    {"emotion": 0.3,  "social": 0.2,  "identity": 0.2,  "moral": 0.3},
    "KOREA":     {"emotion": 0.2,  "social": 0.2,  "identity": 0.4,  "moral": 0.2},
    "LATIN_AM":  {"emotion": 0.4,  "social": 0.2,  "identity": 0.2,  "moral": 0.2},
    "MIDDLE_E":  {"emotion": 0.1,  "social": 0.2,  "identity": 0.2,  "moral": 0.5},
    "AFRICA":    {"emotion": 0.2,  "social": 0.4,  "identity": 0.2,  "moral": 0.2},
    # âœ… ì¶”ê°€ëœ ë‚¨ì•„ì‹œì•„ ë¬¸í™”ê¶Œ
    "SOUTH_ASIA": {"emotion": 0.15, "social": 0.30, "identity": 0.30, "moral": 0.25},
}

# ==================== Scenario Definitions ====================
SCENARIOS = {
    "AI Hiring Bias": {
        "A": [0.20, 0.20, 0.10, 0.50],  # AI ì ìˆ˜ ê·¸ëŒ€ë¡œ ë°˜ì˜ (íš¨ìœ¨/ì„±ê³¼, ê·œë²” ì¤€ìˆ˜ ìœ„ì£¼)
        "B": [0.20, 0.40, 0.30, 0.10],  # í˜•í‰ì„±, ì‚¬íšŒì  ì˜í–¥, ì •ì²´ì„± ë³´í˜¸ ê°•í™”
    },
    "AI Facial Recognition": {
        "A": [0.10, 0.50, 0.10, 0.30],  # AI ëª…ë‹¨ ê·¸ëŒ€ë¡œ ì²´í¬ (ê³µê³µì§ˆì„œ/ì‚¬íšŒ ì•ˆì „ ì¤‘ì‹œ)
        "B": [0.30, 0.20, 0.20, 0.30],  # ì¬ê²€ì¦, ì¸ê¶Œ/ê°œì¸ ë³´í˜¸ë¥¼ ë” ë°˜ì˜
    },
    "Surveillance vs Freedom": {
        "A": [0.10, 0.50, 0.20, 0.20],  # ê°ì‹œ ê°•í™” (ì‚¬íšŒ ì•ˆì „/í†µì œ ìœ„ì£¼)
        "B": [0.30, 0.20, 0.10, 0.40],  # ììœ /ê¶Œë¦¬, ë„ë•ì  ì›ì¹™ ì¤‘ì‹¬
    }
}

# ==================== Sidebar UI ====================
scenario = st.sidebar.selectbox(
    "ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ",
    list(SCENARIOS.keys()),
    index=0
)

selected = st.sidebar.multiselect(
    "ë¬¸í™”ê¶Œ ì„ íƒ",
    list(CULTURES.keys()),
    default=["SOUTH_ASIA"]  # âœ… ê¸°ë³¸ê°’: ë‚¨ì•„ì‹œì•„ë§Œ ì„ íƒ
)

steps = st.sidebar.slider("ë°˜ë³µ ìˆ˜", 50, 500, 200, step=50)
manual = st.sidebar.checkbox("ğŸ® ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜", False)

# ==================== Helper Functions ====================
def normalize(w: dict):
    s = sum(w.values())
    # 0 division ë°©ì§€ + ìµœì†Œê°’ í•˜í•œì„ 
    return {k: max(0.001, v) / s for k, v in w.items()}

# ==================== Agents ì´ˆê¸°í™” ====================
AGENTS = selected
AGENT_WEIGHTS = {}

for a in AGENTS:
    if manual:
        st.sidebar.markdown(f"**{a} ê°€ì¤‘ì¹˜ ì„¤ì •**")
        sliders = {}
        for k in ["emotion", "social", "identity", "moral"]:
            sliders[k] = st.sidebar.slider(
                f"{a} - {k.capitalize()}",
                0.0, 1.0,
                float(CULTURES[a][k])
            )
        AGENT_WEIGHTS[a] = normalize(sliders)
    else:
        # ê¸°ë³¸ ë¬¸í™”ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        AGENT_WEIGHTS[a] = dict(CULTURES[a])

AGENT_SCORES = {a: [] for a in AGENTS}
AGENT_HISTORY = {a: [dict(AGENT_WEIGHTS[a])] for a in AGENTS}
AGENT_ENTROPIES = {a: [] for a in AGENTS}
AGENT_MOVEMENT = {a: [] for a in AGENTS}
GROUP_DIVERGENCE = []
GROUP_AVG_REWARDS = []

# ==================== Simulation Logic ====================
def simulate():
    chosen_scenario = SCENARIOS[scenario]

    for _ in range(steps):
        for a in AGENTS:
            prev = list(AGENT_WEIGHTS[a].values())

            # 1ï¸âƒ£ í˜„ì¬ ê°€ì¹˜ weight ë²¡í„°
            weights_list = list(AGENT_WEIGHTS[a].values())

            # 2ï¸âƒ£ ì„ íƒì§€ A/Bì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚° (ë‚´ì )
            scoreA = float(np.dot(weights_list, chosen_scenario["A"]))
            scoreB = float(np.dot(weights_list, chosen_scenario["B"]))
            choice = "A" if scoreA >= scoreB else "B"

            # 3ï¸âƒ£ ì„ íƒëœ ë³´ìƒ ë²¡í„°
            reward = chosen_scenario[choice]
            keys = list(AGENT_WEIGHTS[a].keys())

            # 4ï¸âƒ£ ë³´ìƒì— ë¹„ë¡€í•´ì„œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            for i, k in enumerate(keys):
                AGENT_WEIGHTS[a][k] += 0.05 * reward[i]

            # 5ï¸âƒ£ ì •ê·œí™” ë° ê¸°ë¡
            AGENT_WEIGHTS[a] = normalize(AGENT_WEIGHTS[a])
            curr = list(AGENT_WEIGHTS[a].values())

            AGENT_HISTORY[a].append(dict(AGENT_WEIGHTS[a]))
            AGENT_SCORES[a].append(float(np.dot(weights_list, reward)))
            AGENT_ENTROPIES[a].append(entropy(curr))
            AGENT_MOVEMENT[a].append(
                np.linalg.norm(np.array(curr) - np.array(prev))
            )

        # 6ï¸âƒ£ ê·¸ë£¹ ì°¨ì› ì§€í‘œ
        if len(AGENTS) > 1:
            mat = np.array([list(AGENT_WEIGHTS[a].values()) for a in AGENTS])
            GROUP_DIVERGENCE.append(float(np.mean(pdist(mat))))
        else:
            GROUP_DIVERGENCE.append(0.0)

        GROUP_AVG_REWARDS.append(
            float(np.mean([np.mean(AGENT_SCORES[a]) for a in AGENTS]))
        )

# ==================== Alerts ====================
def show_alerts():
    for a in AGENTS:
        if len(AGENT_ENTROPIES[a]) > 1:
            delta = AGENT_ENTROPIES[a][-2] - AGENT_ENTROPIES[a][-1]
            if delta > 0.1:
                st.warning(
                    f"âš ï¸ {a}: ì „ëµì´ ê¸‰ê²©íˆ í•œ ë°©í–¥ìœ¼ë¡œ ì ë¦¬ê³  ìˆìŠµë‹ˆë‹¤ (entropy â†“ {delta:.2f})"
                )

# ==================== Caption (ê³ ì • í…ìŠ¤íŠ¸ ìºì‹±) ====================
@st.cache_data(show_spinner=False)
def generate_caption():
    return {
        "fig1": "Figure 1: ë¬¸í™”ê¶Œë³„ ê°€ì¹˜ ì°¨ì›(Emotion, Social, Identity, Moral) ê°€ì¤‘ì¹˜ ê¶¤ì ",
        "fig2": "Figure 2a: ì—”íŠ¸ë¡œí”¼(ì „ëµ ë‚´ë¶€ ë‹¤ì–‘ì„±) ë³€í™”, 2b: ëˆ„ì  ì „ëµ ë³€í™”ëŸ‰",
        "fig3": "Figure 3a: ë¬¸í™”ê¶Œ ê°„ ì „ëµ ë¶„ê¸° ì •ë„(Divergence), 3b: í‰ê·  ë³´ìƒê³¼ì˜ ìƒê´€ê´€ê³„",
    }

# ==================== (ì˜µì…˜) GPT ìš”ì•½ ====================
def gpt_summary():
    try:
        openai.api_key = st.secrets.get("OPENAI_API_KEY")
        trend = pd.DataFrame(GROUP_DIVERGENCE).diff().mean().values[0]
        agents = list(AGENT_HISTORY.keys())
        prompt = (
            f"ë¬¸í™”ê¶Œ ì—ì´ì „íŠ¸ {agents}ê°€ ì‹œë‚˜ë¦¬ì˜¤ '{scenario}'ì—ì„œ "
            f"A/B ì „ëµ ì„ íƒì„ ë°˜ë³µ í•™ìŠµí•œ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì¤˜. "
            f"ì „ëµ ë‹¤ì–‘ì„±(ì—”íŠ¸ë¡œí”¼)ì™€ ë³´ìƒ(í‰ê·  ë³´ìƒ)ì˜ ê´€ê³„ë„ í¬í•¨í•´ì„œ 5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
        )
        out = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
        )
        st.info(out["choices"][0]["message"]["content"])
    except Exception as e:
        st.error(f"GPT ìš”ì•½ ì‹¤íŒ¨: {e}")

# ==================== Run & Display ====================
if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    if len(AGENTS) == 0:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¬¸í™”ê¶Œì„ ì„ íƒí•˜ì„¸ìš”.")
    else:
        simulate()
        captions = generate_caption()

        # ---------- Figure 1: ê°€ì¹˜ ì°¨ì› ê¶¤ì  ----------
        st.subheader("ğŸ“Š " + captions["fig1"])
        for dim in ["emotion", "social", "identity", "moral"]:
            fig, ax = plt.subplots()
            for a in AGENT_HISTORY:
                ax.plot([w[dim] for w in AGENT_HISTORY[a]], label=a)
            ax.set_title(f"{dim.capitalize()} Weight Trajectory")
            ax.legend()
            st.pyplot(fig)

        # ---------- Figure 2: ì—”íŠ¸ë¡œí”¼ / ëˆ„ì  ë³€í™” ----------
        st.subheader("ğŸ“ˆ " + captions["fig2"])

        # 2a. ì—”íŠ¸ë¡œí”¼
        fig1, ax1 = plt.subplots()
        for a in AGENT_ENTROPIES:
            ax1.plot(AGENT_ENTROPIES[a], label=a)
        ax1.set_title("Entropy of Strategy Distribution")
        ax1.legend()
        st.pyplot(fig1)

        # 2b. ëˆ„ì  ë³€í™”ëŸ‰
        fig2, ax2 = plt.subplots()
        for a in AGENT_MOVEMENT:
            ax2.plot(np.cumsum(AGENT_MOVEMENT[a]), label=a)
        ax2.set_title("Cumulative Strategic Change")
        ax2.legend()
        st.pyplot(fig2)

        # ---------- Figure 3: Divergence & Reward ----------
        st.subheader("ğŸ“‰ " + captions["fig3"])

        # 3a. ê·¸ë£¹ Divergence
        fig3, ax3 = plt.subplots()
        ax3.plot(GROUP_DIVERGENCE, label="Ethical Divergence")
        ax3.set_title("Group Ethical Divergence Over Time")
        ax3.legend()
        st.pyplot(fig3)

        # 3b. Divergence vs Avg Reward
        fig4, ax4 = plt.subplots()
        ax4.scatter(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
        if len(GROUP_DIVERGENCE) > 1 and len(set(GROUP_DIVERGENCE)) > 1:
            r, p = pearsonr(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
            ax4.set_title(f"Divergence vs Avg Reward (r={r:.2f}, p={p:.3f})")
        else:
            ax4.set_title("Divergence vs Avg Reward (í‘œë³¸ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ìƒìˆ˜ê°€ ë§ìŒ)")
        st.pyplot(fig4)

        # ---------- ìµœì¢… ì „ëµ ìš”ì•½ ----------
        st.subheader("ğŸ“„ ìµœì¢… ì „ëµ ìš”ì•½ (ë§ˆì§€ë§‰ ìŠ¤í… ê¸°ì¤€)")
        df = pd.DataFrame(
            [{"Agent": a, **AGENT_HISTORY[a][-1]} for a in AGENTS]
        )
        st.dataframe(df.set_index("Agent"))

        st.download_button(
            "ğŸ“¥ Save CSV",
            data=df.to_csv(index=False),
            file_name="final_strategies.csv"
        )

        # ---------- ê²½ê³  ----------
        st.subheader("ğŸ“¡ ì „ëµ ë¶„ê¸° ê²½ê³ ")
        show_alerts()

        # ---------- GPT ìš”ì•½ (ì˜µì…˜ ë²„íŠ¼) ----------
        if st.button("ğŸ§  GPTë¡œ ê²°ê³¼ ìš”ì•½ë°›ê¸°"):
            gpt_summary()

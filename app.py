# streamlit_app.py â€“ Cultural Ethics Simulator
import streamlit as st

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from scipy.stats import entropy, pearsonr

st.set_page_config(page_title="Ethics GPT Sim", layout="wide")
st.title("ğŸŒ Global AI Ethics Simulator")

# ----------------------------- Configuration -----------------------------
CULTURES = {
    "USA":     {"emotion": 0.3, "social": 0.1, "identity": 0.3, "moral": 0.3},
    "CHINA":   {"emotion": 0.1, "social": 0.5, "identity": 0.2, "moral": 0.2},
    "EUROPE":  {"emotion": 0.3, "social": 0.2, "identity": 0.2, "moral": 0.3},
    "KOREA":   {"emotion": 0.2, "social": 0.2, "identity": 0.4, "moral": 0.2},
    "LATIN_AM": {"emotion": 0.4, "social": 0.2, "identity": 0.2, "moral": 0.2},
    "MIDDLE_E": {"emotion": 0.1, "social": 0.2, "identity": 0.2, "moral": 0.5},
    "AFRICA":  {"emotion": 0.2, "social": 0.4, "identity": 0.2, "moral": 0.2},
    # âœ… ì¶”ê°€ëœ ë‚¨ì•„ì‹œì•„ ë¬¸í™”ê¶Œ
    "SOUTH_ASIA": {"emotion": 0.15, "social": 0.30, "identity": 0.30, "moral": 0.25},
}

# ----------------------------- Scenario Definitions -----------------------------
SCENARIOS = {
    "AI Hiring Bias": {
        "A": [0.20, 0.20, 0.10, 0.50],  # AI ì ìˆ˜ ê·¸ëŒ€ë¡œ ë°˜ì˜
        "B": [0.20, 0.40, 0.30, 0.10],  # í˜•í‰ì„± ê³ ë ¤ ìˆ˜ì •
    },
    "AI Facial Recognition": {
        "A": [0.10, 0.50, 0.10, 0.30],  # AI ëª…ë‹¨ ê·¸ëŒ€ë¡œ ì²´í¬
        "B": [0.30, 0.20, 0.20, 0.30],  # ì¬ê²€ì¦ ì ˆì°¨ ì§„í–‰
    },
    "Surveillance vs Freedom": {
        "A": [0.10, 0.50, 0.20, 0.20],  # ê°ì‹œ ê°•í™”
        "B": [0.30, 0.20, 0.10, 0.40],  # ììœ  ë³´ì¥
    }
}

# ----------------------------- Sidebar UI -----------------------------
scenario = st.sidebar.selectbox(
    "ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ",
    list(SCENARIOS.keys()),
    index=0
)

selected = st.sidebar.multiselect(
    "ë¬¸í™”ê¶Œ ì„ íƒ",
    list(CULTURES.keys()),
    default=["SOUTH_ASIA"]  # âœ… ê¸°ë³¸ê°’: ë‚¨ì•„ì‹œì•„
)

steps = st.sidebar.slider("ë°˜ë³µ ìˆ˜", 50, 500, 200, step=50)
manual = st.sidebar.checkbox("ğŸ® ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜", False)

def normalize(w):
    s = sum(w.values())
    return {k: max(0.001, v)/s for k, v in w.items()}

AGENTS = selected
AGENT_WEIGHTS = {}
for a in AGENTS:
    if manual:
        st.sidebar.markdown(f"**{a}**")
        w = {
            k: st.sidebar.slider(
                f"{a} - {k.capitalize()}",
                0.0, 1.0,
                CULTURES[a][k]
            )
            for k in ["emotion", "social", "identity", "moral"]
        }
        AGENT_WEIGHTS[a] = normalize(w)
    else:
        AGENT_WEIGHTS[a] = dict(CULTURES[a])

AGENT_SCORES = {a: [] for a in AGENTS}
AGENT_HISTORY = {a: [dict(AGENT_WEIGHTS[a])] for a in AGENTS}
AGENT_ENTROPIES = {a: [] for a in AGENTS}
AGENT_MOVEMENT = {a: [] for a in AGENTS}
GROUP_DIVERGENCE = []
GROUP_AVG_REWARDS = []

# ----------------------------- Simulation Logic -----------------------------
def simulate():
    chosen_scenario = SCENARIOS[scenario]
    for _ in range(steps):
        for a in AGENTS:
            prev = list(AGENT_WEIGHTS[a].values())

            # ----------- ì„ íƒì§€ ì ìˆ˜ ê³„ì‚° -----------
            weights_list = list(AGENT_WEIGHTS[a].values())
            scoreA = np.dot(weights_list, chosen_scenario["A"])
            scoreB = np.dot(weights_list, chosen_scenario["B"])
            choice = "A" if scoreA >= scoreB else "B"

            # ----------- ì„ íƒëœ ë³´ìƒ ë°˜ì˜ -----------
            reward = chosen_scenario[choice]
            keys = list(AGENT_WEIGHTS[a].keys())
            for i, k in enumerate(keys):
                AGENT_WEIGHTS[a][k] += 0.05 * reward[i]

            # ----------- ì •ê·œí™” ë° ê¸°ë¡ -----------
            AGENT_WEIGHTS[a] = normalize(AGENT_WEIGHTS[a])
            curr = list(AGENT_WEIGHTS[a].values())
            AGENT_HISTORY[a].append(dict(AGENT_WEIGHTS[a]))
            AGENT_SCORES[a].append(float(np.dot(weights_list, reward)))
            AGENT_ENTROPIES[a].append(entropy(curr))
            AGENT_MOVEMENT[a].append(np.linalg.norm(np.array(curr) - np.array(prev)))

        # ----------- ê·¸ë£¹ ìˆ˜ì¤€ ê³„ì‚° -----------
        mat = np.array([list(AGENT_WEIGHTS[a].values()) for a in AGENTS])
        GROUP_DIVERGENCE.append(np.mean(pdist(mat)))
        GROUP_AVG_REWARDS.append(
            np.mean([np.mean(AGENT_SCORES[a]) for a in AGENTS])
        )

# ----------------------------- Display -----------------------------
def show_alerts():
    for a in AGENTS:
        if len(AGENT_ENTROPIES[a]) > 1:
            delta = AGENT_ENTROPIES[a][-2] - AGENT_ENTROPIES[a][-1]
            if delta > 0.1:
                st.warning(
                    f"âš ï¸ {a}: ì „ëµì´ ê¸‰ê²©íˆ ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤ (entropy â†“ {delta:.2f})"
                )

@st.cache_data(show_spinner=False)
def generate_caption():
    return {
        "fig1": "Figure 1: Trajectories of strategic dimensions (Emotion, Social, Identity, Moral) per culture",
        "fig2": "Figure 2a: Entropy trends (internal diversity); 2b: Cumulative change of strategies",
        "fig3": "Figure 3a: Group divergence over time; 3b: Correlation with average reward"
    }

def gpt_summary():
    # openai ë¯¸ì‚¬ìš©: í˜¸ì¶œ ì•ˆ í•˜ë©´ ê·¸ëƒ¥ ë¬´ì‹œë˜ëŠ” í•¨ìˆ˜
    try:
        openai.api_key = st.secrets.get("OPENAI_API_KEY")
        trend = pd.DataFrame(GROUP_DIVERGENCE).diff().mean().values[0]
        agents = list(AGENT_HISTORY.keys())
        prompt = f"ë¬¸í™”ê¶Œ ì—ì´ì „íŠ¸ {agents}ê°€ ì „ëµ ê¶¤ì ì„ í•™ìŠµí•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì¤˜. ì „ëµ ë‹¤ì–‘ì„±ê³¼ ë³´ìƒì˜ ê´€ê³„ë„ í¬í•¨í•´ì„œ 5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
        out = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        st.info(out["choices"][0]["message"]["content"])
    except Exception as e:
        st.error(f"GPT ìš”ì•½ ì‹¤íŒ¨: {e}")

# ----------------------------- Run -----------------------------
if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    simulate()
    captions = generate_caption()

    st.subheader("ğŸ“Š " + captions["fig1"])
    for dim in ["emotion", "social", "identity", "moral"]:
        fig, ax = plt.subplots()
        for a in AGENT_HISTORY:
            ax.plot([w[dim] for w in AGENT_HISTORY[a]], label=a)
        ax.set_title(f"{dim.capitalize()} Weight")
        ax.legend()
        st.pyplot(fig)

    st.subheader("ğŸ“ˆ " + captions["fig2"])
    fig1, ax1 = plt.subplots()
    for a in AGENT_ENTROPIES:
        ax1.plot(AGENT_ENTROPIES[a], label=a)
    ax1.set_title("Entropy of Strategy Distribution")
    ax1.legend()
    st.pyplot(fig1)

    fig2, ax2 = plt.subplots()
    for a in AGENT_MOVEMENT:
        ax2.plot(np.cumsum(AGENT_MOVEMENT[a]), label=a)
    ax2.set_title("Cumulative Strategic Change")
    ax2.legend()
    st.pyplot(fig2)

    st.subheader("ğŸ“‰ " + captions["fig3"])
    fig3, ax3 = plt.subplots()
    ax3.plot(GROUP_DIVERGENCE, label="Ethical Divergence")
    ax3.set_title("Group Ethical Divergence")
    ax3.legend()
    st.pyplot(fig3)

    fig4, ax4 = plt.subplots()
    ax4.scatter(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    r, p = pearsonr(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    ax4.set_title(f"Divergence vs Avg Reward (r={r:.2f}, p={p:.3f})")
    st.pyplot(fig4)

    st.subheader("ğŸ“„ ì „ëµ ìš”ì•½")
    df = pd.DataFrame(
        [{"Agent": a, **AGENT_HISTORY[a][-1]} for a in AGENTS]
    )
    st.dataframe(df.set_index("Agent"))
    st.download_button(
        "ğŸ“¥ Save CSV",
        data=df.to_csv(index=False),
        file_name="final_strategies.csv"
    )

    st.subheader("ğŸ“¡ ì „ëµ ë¶„ê¸° ê²½ê³ ")
    show_alerts()

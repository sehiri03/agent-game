# app.py â€“ Cultural Ethics Simulator
import streamlit as st

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from scipy.stats import entropy, pearsonr

# ----------------------------- App Config -----------------------------
st.set_page_config(page_title="Ethics GPT Sim", layout="wide")
st.title("ðŸŒ Global AI Ethics Simulator")

# ----------------------------- Configuration -----------------------------
CULTURES = {
    "USA":     {"emotion": 0.3, "social": 0.1, "identity": 0.3, "moral": 0.3},
    "CHINA":   {"emotion": 0.1, "social": 0.5, "identity": 0.2, "moral": 0.2},
    "EUROPE":  {"emotion": 0.3, "social": 0.2, "identity": 0.2, "moral": 0.3},
    "KOREA":   {"emotion": 0.2, "social": 0.2, "identity": 0.4, "moral": 0.2},
    "LATIN_AM": {"emotion": 0.4, "social": 0.2, "identity": 0.2, "moral": 0.2},
    "MIDDLE_E": {"emotion": 0.1, "social": 0.2, "identity": 0.2, "moral": 0.5},
    "AFRICA":  {"emotion": 0.2, "social": 0.4, "identity": 0.2, "moral": 0.2},
    # âœ… ì¶”ê°€ëœ ë‚¨ì•„ì‹œì•„ ë¬¸í™”ê¶Œ
    "SOUTH_ASIA": {"emotion": 0.15, "social": 0.30, "identity": 0.30, "moral": 0.25},
}

# ----------------------------- Scenario Definitions -----------------------------
SCENARIOS = {
    "AI Hiring Bias": {
        "A": [0.20, 0.20, 0.10, 0.50],  # AI ì ìˆ˜ ê·¸ëŒ€ë¡œ ë°˜ì˜
        "B": [0.20, 0.40, 0.30, 0.10],  # í˜•í‰ì„± ê³ ë ¤ ìˆ˜ì •
    },
    "AI Facial Recognition": {
        "A": [0.10, 0.50, 0.10, 0.30],  # AI ëª…ë‹¨ ê·¸ëŒ€ë¡œ ì²´í¬
        "B": [0.30, 0.20, 0.20, 0.30],  # ìž¬ê²€ì¦ ì ˆì°¨ ì§„í–‰
    },
    "Surveillance vs Freedom": {
        "A": [0.10, 0.50, 0.20, 0.20],  # ê°ì‹œ ê°•í™”
        "B": [0.30, 0.20, 0.10, 0.40],  # ìžìœ  ë³´ìž¥
    }
}

# ----------------------------- Sidebar UI -----------------------------
scenario = st.sidebar.selectbox(
    "ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ",
    list(SCENARIOS.keys()),
    index=0
)

selected = st.sidebar.multiselect(
    "ë¬¸í™”ê¶Œ ì„ íƒ",
    list(CULTURES.keys()),
    default=["SOUTH_ASIA"]  # âœ… ê¸°ë³¸ê°’: ë‚¨ì•„ì‹œì•„ë§Œ ì„ íƒ
)

steps = st.sidebar.slider("ë°˜ë³µ ìˆ˜", 50, 500, 200, step=50)
manual = st.sidebar.checkbox("ðŸŽ® ì‚¬ìš©ìž ì •ì˜ ê°€ì¤‘ì¹˜", False)

# ----------------------------- Helper -----------------------------
def normalize(w):
    s = sum(w.values())
    return {k: max(0.001, v)/s for k, v in w.items()}

# ----------------------------- Agents Init -----------------------------
AGENTS = selected
AGENT_WEIGHTS = {}

for a in AGENTS:
    if manual:
        st.sidebar.markdown(f"**{a} ê°€ì¤‘ì¹˜ ì„¤ì •**")
        w = {
            k: st.sidebar.slider(
                f"{a} - {k.capitalize()}",
                0.0, 1.0,
                float(CULTURES[a][k])
            )
            for k in ["emotion", "social", "identity", "moral"]
        }
        AGENT_WEIGHTS[a] = normalize(w)
    else:
        AGENT_WEIGHTS[a] = dict(CULTURES[a])

AGENT_SCORES = {a: [] for a in AGENTS}
AGENT_HISTORY = {a: [dict(AGENT_WEIGHTS[a])] for a in AGENTS}
AGENT_ENTROPIES = {a: [] for a in AGENTS}
AGENT_MOVEMENT = {a: [] for a in AGENTS}
GROUP_DIVERGENCE = []
GROUP_AVG_REWARDS = []

# ----------------------------- Simulation Logic -----------------------------
def simulate():
    chosen_scenario = SCENARIOS[scenario]

    for _ in range(steps):
        for a in AGENTS:
            prev = list(AGENT_WEIGHTS[a].values())

            # ----------- ì„ íƒì§€ ì ìˆ˜ ê³„ì‚° -----------
            weights_list = list(AGENT_WEIGHTS[a].values())
            scoreA = np.dot(weights_list, chosen_scenario["A"])
            scoreB = np.dot(weights_list, chosen_scenario["B"])
            choice = "A" if scoreA >= scoreB else "B"

            # ----------- ì„ íƒëœ ë³´ìƒ ë°˜ì˜ -----------
            reward = chosen_scenario[choice]
            keys = list(AGENT_WEIGHTS[a].keys())
            for i, k in enumerate(keys):
                AGENT_WEIGHTS[a][k] += 0.05 * reward[i]

            # ----------- ì •ê·œí™” ë° ê¸°ë¡ -----------
            AGENT_WEIGHTS[a] = normalize(AGENT_WEIGHTS[a])
            curr = list(AGENT_WEIGHTS[a].values())

            AGENT_HISTORY[a].append(dict(AGENT_WEIGHTS[a]))
            AGENT_SCORES[a].append(float(np.dot(weights_list, reward)))
            AGENT_ENTROPIES[a].append(entropy(curr))
            AGENT_MOVEMENT[a].append(np.linalg.norm(np.array(curr) - np.array(prev)))

        # ----------- ê·¸ë£¹ ìˆ˜ì¤€ ê³„ì‚° -----------
        if len(AGENTS) > 1:
            mat = np.array([list(AGENT_WEIGHTS[a].values()) for a in AGENTS])
            GROUP_DIVERGENCE.append(float(np.mean(pdist(mat))))
        else:
            GROUP_DIVERGENCE.append(0.0)

        GROUP_AVG_REWARDS.append(
            float(np.mean([np.mean(AGENT_SCORES[a]) for a in AGENTS]))
        )

# ----------------------------- Display -----------------------------
def show_alerts():
    for a in AGENTS:
        if len(AGENT_ENTROPIES[a]) > 1:
            delta = AGENT_ENTROPIES[a][-2] - AGENT_ENTROPIES[a][-1]
            if delta > 0.1:
                st.warning(
                    f"âš ï¸ {a}: ì „ëžµì´ ê¸‰ê²©ížˆ ì§‘ì¤‘ë˜ê³  ìžˆìŠµë‹ˆë‹¤ (entropy â†“ {delta:.2f})"
                )

@st.cache_data(show_spinner=False)
def generate_caption():
    return {
        "fig1": "Figure 1: Trajectories of strategic dimensions (Emotion, Social, Identity, Moral) per culture",
        "fig2": "Figure 2a: Entropy trends (internal diversity); 2b: Cumulative change of strategies",
        "fig3": "Figure 3a: Group divergence over time; 3b: Correlation with average reward"
    }

# ----------------------------- Run -----------------------------
if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œìž‘"):
    if len(AGENTS) == 0:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¬¸í™”ê¶Œì„ ì„ íƒí•˜ì„¸ìš”.")
    else:
        simulate()
        captions = generate_caption()

        st.subheader("ðŸ“Š " + captions["fig1"])
        for dim in ["emotion", "social", "identity", "moral"]:
            fig, ax = plt.subplots()
            for a in AGENT_HISTORY:
                ax.plot([w[dim] for w in AGENT_HISTORY[a]], label=a)
            ax.set_title(f"{dim.capitalize()} Weight")
            ax.legend()
            st.pyplot(fig)

        st.subheader("ðŸ“ˆ " + captions["fig2"])
        fig1, ax1 = plt.subplots()
        for a in AGENT_ENTROPIES:
            ax1.plot(AGENT_ENTROPIES[a], label=a)
        ax1.set_title("Entropy of Strategy Distribution")
        ax1.legend()
        st.pyplot(fig1)

        fig2, ax2 = plt.subplots()
        for a in AGENT_MOVEMENT:
            ax2.plot(np.cumsum(AGENT_MOVEMENT[a]), label=a)
        ax2.set_title("Cumulative Strategic Change")
        ax2.legend()
        st.pyplot(fig2)

        st.subheader("ðŸ“‰ " + captions["fig3"])
        fig3, ax3 = plt.subplots()
        ax3.plot(GROUP_DIVERGENCE, label="Ethical Divergence")
        ax3.set_title("Group Ethical Divergence")
        ax3.legend()
        st.pyplot(fig3)

        fig4, ax4 = plt.subplots()
        ax4.scatter(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
        if len(GROUP_DIVERGENCE) > 1 and len(set(GROUP_DIVERGENCE)) > 1:
            r, p = pearsonr(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
            ax4.set_title(f"Divergence vs Avg Reward (r={r:.2f}, p={p:.3f})")
        else:
            ax4.set_title("Divergence vs Avg Reward")
        st.pyplot(fig4)

        st.subheader("ðŸ“„ ì „ëžµ ìš”ì•½")
        df = pd.DataFrame(
            [{"Agent": a, **AGENT_HISTORY[a][-1]} for a in AGENTS]
        )
        st.dataframe(df.set_index("Agent"))
        st.download_button(
            "ðŸ“¥ Save CSV",
            data=df.to_csv(index=False),
            file_name="final_strategies.csv"
        )

        st.subheader("ðŸ“¡ ì „ëžµ ë¶„ê¸° ê²½ê³ ")
        show_alerts()
